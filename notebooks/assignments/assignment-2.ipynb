{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2baaa681-e813-428b-9010-4508b7291011",
   "metadata": {},
   "source": [
    "# Programming Assignment-2\n",
    "The goal of this assingment is to allow you to practice several the following things in Python:\n",
    "1. Perfoming typical data processing (or preprocessing if you prefer). This includes all the typical data wraning such as creating news variables, combining several datasets and more \n",
    "2. Running explolatory data analysis including basic plotting of variables \n",
    "3. Perfoming basic inferential statisticals using statsmodels and scipy to run hypythesis testing and build simple statistial or econometric models.\n",
    "\n",
    "## Datasets \n",
    "For this assignment, you will use the following datasets:\n",
    "### Rwanda Health Indicators\n",
    "The Excel file was generated by combining multiple CSV files, each containing data on different health indicators for Rwanda, So that each sheet in the file represent one such indicator. See below some of the input files which were used:\n",
    "- `access-to-health-care_subnational_rwa`\n",
    "- `child-mortality-rates_subnational_rwa`\n",
    "- `dhs-mobile_subnational_rwa`\n",
    "\n",
    "You can download the dataset from [here](https://docs.google.com/spreadsheets/d/1uvTQYS22VfXXo1Hwkm1frFx_bKkLQkcf/edit?usp=share_link&ouid=113302179168925233984&rtpof=true&sd=true).\n",
    "### Nights lights Data\n",
    "- Please download it [here](https://drive.google.com/file/d/1f_4fiqxIejly0YmC088s9bxOfrABv9Sz/view?usp=sharing) and check the documentation in the cells below. \n",
    "\n",
    "### Popupation Dataset\n",
    "- Please download it [here](https://drive.google.com/file/d/1FWEFGdN-xDuFH1jmt0hr4F8Xc3Y5XzvB/view?usp=share_link) and check the documentation and metadata in the class notebooks.\n",
    "\n",
    "\n",
    "## Submission Guidelines \n",
    "- Please guidelines and complete all steps in the [GitHub Workflow](https://dmatekenya.github.io/AIMS-DSCBI/course-requirements/github-workflow.html)\n",
    "- Once you have completed your assignment, push changes to your repository.\n",
    "- Send a link (copy from within GitHub) to your notebook to the tutors/teaching assistants\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a0961aa",
   "metadata": {},
   "source": [
    "# Import Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "30d3cb64",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "2532d7d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\geoffrey-risa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\geoffrey-risa\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from openpyxl) (2.0.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb0234e",
   "metadata": {},
   "source": [
    "# Setup Input Folders\n",
    "\n",
    "As usual, it is good practice to set up input folders using the [`pathlib`](https://docs.python.org/3/library/pathlib.html) package. In this section, make sure to define the folders where your data is stored on your machine.\n",
    "\n",
    "I find it helpful to set up the working directory and input data folders right at the start of the notebook. To keep things organized, I use the naming convention: `FILE_{NAME}` for files and `DIR_{NAME}` for folders. We use capital letters because these are global variables that will be referenced throughout the notebook.\n",
    "\n",
    "We'll be using the [`pathlib`](https://docs.python.org/3/library/pathlib.html) library, which offers several advantages over traditional string-based path handling:\n",
    "\n",
    "- **Cross-platform compatibility** - automatically handles path separators (`/` vs `\\`) across different operating systems\n",
    "- **Object-oriented approach** - paths are objects with useful methods rather than strings\n",
    "- **Intuitive syntax** - use `/` operator to join paths naturally: `parent_dir / \"subfolder\" / \"file.txt\"`\n",
    "- **Built-in path operations** - methods like `.exists()`, `.is_file()`, `.parent`, `.stem`, and `.suffix`\n",
    "- **Safer path manipulation** - reduces errors from manual string concatenation and splitting\n",
    "\n",
    "This is the recommended approach for managing file paths in modern Python development.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8273ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Uncomment the following lines and add your code to define the directories and files\n",
    "DIR_DATA = Path.cwd().parents[0].joinpath(\"assignments/data\")\n",
    "FILE_EXCEL = DIR_DATA/\"RW-Health-Data.xlsx\"\n",
    "\n",
    "FILE_POP_MW = DIR_DATA/\"rwa-cell-pop.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a15bb61",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f2778b3b",
   "metadata": {},
   "source": [
    "# Part 1: Processing Excel Files\n",
    "The primary goal is to preprocess an [Excel file](https://docs.google.com/spreadsheets/d/1uvTQYS22VfXXo1Hwkm1frFx_bKkLQkcf/edit?usp=share_link&ouid=113302179168925233984&rtpof=true&sd=true) with multiple sheets into a unified CSV dataset that consolidates multiple indicators. Having all indicators in a single file at the same analytical unit (national, subnational) is more efficient than managing separate files and enables easier cross-indicator analysis.\n",
    "\n",
    "## Task 1: Generate National-Level Summaries\n",
    "\n",
    "For each indicator, compute a single national-level value using appropriate aggregation functions such as **mean**, **sum** or **count**. For this one, all available indicators can be summarized at national level, so we will have a CSV file with one row and \n",
    "\n",
    "### Expected Output Structure\n",
    "1. **DataFrame display** in Jupyter Notebook\n",
    "2. **CSV file** with columns:\n",
    "- `indicator_name`: Name of the indicator\n",
    "- `aggregated_value`: Computed national value\n",
    "- `indicator_year`: Survey year or something similar\n",
    "- `survey_name`: Name of the survey where information is coming from\n",
    "- `aggregation_method`: Statistical method used (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "eeb5b790",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = pd.read_excel(FILE_EXCEL, sheet_name=None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "144965e7",
   "metadata": {},
   "source": [
    "## Task 2: Subnational-Level Indicator Dataset\n",
    "\n",
    "Create a merged dataset for indicators with subnational data (ADM2/ADM3 levels), ensuring spatial alignment and consistent administrative boundaries.\n",
    "\n",
    "### Expected Output Structure\n",
    "   - `indicator_name`: Name of the indicator\n",
    "   - `aggregated_value`: Computed national value\n",
    "   - `indicator_year`: Survey year or something similar\n",
    "   - `survey_name`: Name of the survey where information is coming from\n",
    "   - `aggregation_method`: Statistical method used (optional)\n",
    "\n",
    "This structure enables both single-indicator and multi-indicator analysis at the subnational level.\n",
    "\n",
    "#####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1e2755c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mdf\u001b[49m.groupby([\u001b[33m'\u001b[39m\u001b[33mindicator_name\u001b[39m\u001b[33m'\u001b[39m])[\u001b[33m'\u001b[39m\u001b[33mValue\u001b[39m\u001b[33m'\u001b[39m].mean().reset_index().rename(columns={\u001b[33m'\u001b[39m\u001b[33mValue\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33mAggregated_Value\u001b[39m\u001b[33m'\u001b[39m})  \u001b[38;5;66;03m#group by indicator_name and calculate mean\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "df.groupby(['indicator_name'])['Value'].mean().reset_index().rename(columns={'Value': 'Aggregated_Value'})  #group by indicator_name and calculate mean"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8169202f",
   "metadata": {},
   "source": [
    "## Introduction to Nightlights Dataset\n",
    "\n",
    "## What is Nightlight Data?\n",
    "\n",
    "Nightlight data is satellite imagery capturing artificial light emissions from Earth's surface during nighttime. Satellites like VIIRS collect this data regularly, providing an **objective, real-time measure of human economic activity and development**.\n",
    "\n",
    "### Raw Data: Radiance Measurements\n",
    "The fundamental measurement in nightlight data is **radiance** - the amount of light energy detected by satellite sensors, measured in **nanowatts per square centimeter per steradian (nW/cm²/sr)**. Each pixel in satellite imagery contains a radiance value representing the light intensity from that specific location on Earth's surface.\n",
    "\n",
    "### Annual Composite Generation\n",
    "This dataset was created from **annual composite images** using VIIRS nightlight files for Rwanda. Annual composites are generated by:\n",
    "\n",
    "- **Aggregating daily/monthly observations** throughout each year (2015, 2020, 2024)\n",
    "- **Filtering out temporary light sources** (fires, lightning, aurora)\n",
    "- **Removing cloud-affected observations** to ensure clear measurements\n",
    "- **Averaging or taking median values** to create stable, representative annual measurements\n",
    "- **Masking techniques** to exclude areas with unreliable data\n",
    "\n",
    "The files used include both **average composites** (`average_masked`) and **median composites** (`median_masked`), with **cloud-free versions** (`vcmslcfg`) preferred over cloud-inclusive versions (`vcmcfg`) for more accurate measurements.\n",
    "\n",
    "### Why Use Nightlight Data?\n",
    "\n",
    "- **Consistent global coverage** - Available everywhere, regardless of local data quality\n",
    "- **Real-time updates** - More current than traditional economic statistics\n",
    "- **Objective measurement** - Not subject to reporting biases\n",
    "- **High resolution** - Captures local development patterns\n",
    "- **Proxy for development** - Light intensity correlates with economic activity, infrastructure, and quality of life\n",
    "\n",
    "## Dataset Overview \n",
    "\n",
    "- **6,507 observations** across Rwanda's administrative cells\n",
    "- **Three time periods**: 2015, 2020, 2024\n",
    "- **Cell-level data** - Rwanda's smallest administrative units\n",
    "- Allows temporal analysis of development trends\n",
    "\n",
    "---\n",
    "\n",
    "## Variable Definitions\n",
    "\n",
    "### Administrative Identifiers\n",
    "- **`cell_id`** - Unique identifier for linking with other datasets\n",
    "- **`province_name`** - Province (5 total in Rwanda)\n",
    "- **`district_name`** - District (30 total in Rwanda) \n",
    "- **`sector_name`** - Administrative level between district and cell\n",
    "- **`cell_name`** - Specific cell name\n",
    "\n",
    "### Core Nightlight Measurements\n",
    "\n",
    "#### `total_nightlight`\n",
    "- **Sum of all radiance values** within cell boundaries\n",
    "- **Key indicator** of overall economic activity/development\n",
    "- Higher values = more total development\n",
    "\n",
    "#### `mean_nightlight` \n",
    "- **Average radiance** per pixel\n",
    "- Indicates development intensity regardless of cell size\n",
    "- Useful for comparing cells of different areas\n",
    "\n",
    "#### `median_nightlight`\n",
    "- **Middle radiance value** of all pixels (less sensitive to outliers)\n",
    "- Better represents typical lighting in unevenly developed areas\n",
    "\n",
    "#### `max_nightlight`\n",
    "- **Highest radiance** within cell\n",
    "- Indicates major infrastructure (hospitals, commercial centers)\n",
    "\n",
    "#### `min_nightlight` & `std_nightlight`\n",
    "- Minimum radiance and standard deviation\n",
    "- High std = uneven development within cell\n",
    "\n",
    "### Spatial Coverage Indicators\n",
    "\n",
    "#### `pixel_count`\n",
    "- **Total pixels** in cell (indicates geographic size)\n",
    "- Used to normalize other measurements\n",
    "\n",
    "#### `lit_pixel_count`\n",
    "- **Number of pixels with detectable light** (radiance > 0)\n",
    "- Shows spatial extent of development\n",
    "\n",
    "#### `lit_pixel_percentage`\n",
    "- **Percentage of cell area with lighting**\n",
    "- Formula: `(lit_pixel_count ÷ pixel_count) × 100`\n",
    "- **0% = completely dark, 100% = fully developed**\n",
    "\n",
    "#### `year`\n",
    "- Time period: 2015, 2020, or 2024"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "784d2e72",
   "metadata": {},
   "source": [
    "# Part-2: Demographic and Nightlights Data\n",
    "\n",
    "## Part A: Varible Generation and Data Integration\n",
    "\n",
    "### Population Dataset Variables (`rwa-cell-pop.csv`):\n",
    "Create the following derived variables:\n",
    "- **`dependency_ratio`** - `(children_under_five_2020 + elderly_60_plus_2020) / working_age_population * 100`\n",
    "- **`people_per_building`** - `general_2020 / building_count`\n",
    "- **`working_age_population`** - `general_2020 - children_under_five_2020 - elderly_60_plus_2020`\n",
    "- **`infrastructure_index`** - Your own formula that incorporates `people_per_building` and other relevant variables to measure infrastructure adequacy. Document and justify your `infrastructure_index` methodology, explaining how `people_per_building` and other variables contribute to measuring infrastructure pressure.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f0479d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32bdd829",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'c:\\\\Users\\\\Geoffrey-RISA\\\\Documents\\\\GitHub\\\\AIMS-DSCBI\\\\notebooks\\\\assignments\\\\data\\\\rwa-cell-pop'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m df = \u001b[43mpd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mFILE_EXCEL\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Geoffrey-RISA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[39m, in \u001b[36mread_csv\u001b[39m\u001b[34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[39m\n\u001b[32m   1013\u001b[39m kwds_defaults = _refine_defaults_read(\n\u001b[32m   1014\u001b[39m     dialect,\n\u001b[32m   1015\u001b[39m     delimiter,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1022\u001b[39m     dtype_backend=dtype_backend,\n\u001b[32m   1023\u001b[39m )\n\u001b[32m   1024\u001b[39m kwds.update(kwds_defaults)\n\u001b[32m-> \u001b[39m\u001b[32m1026\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Geoffrey-RISA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[39m, in \u001b[36m_read\u001b[39m\u001b[34m(filepath_or_buffer, kwds)\u001b[39m\n\u001b[32m    617\u001b[39m _validate_names(kwds.get(\u001b[33m\"\u001b[39m\u001b[33mnames\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[32m    619\u001b[39m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m620\u001b[39m parser = \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    622\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[32m    623\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Geoffrey-RISA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[39m, in \u001b[36mTextFileReader.__init__\u001b[39m\u001b[34m(self, f, engine, **kwds)\u001b[39m\n\u001b[32m   1617\u001b[39m     \u001b[38;5;28mself\u001b[39m.options[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m] = kwds[\u001b[33m\"\u001b[39m\u001b[33mhas_index_names\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m   1619\u001b[39m \u001b[38;5;28mself\u001b[39m.handles: IOHandles | \u001b[38;5;28;01mNone\u001b[39;00m = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1620\u001b[39m \u001b[38;5;28mself\u001b[39m._engine = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Geoffrey-RISA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1880\u001b[39m, in \u001b[36mTextFileReader._make_engine\u001b[39m\u001b[34m(self, f, engine)\u001b[39m\n\u001b[32m   1878\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1879\u001b[39m         mode += \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1880\u001b[39m \u001b[38;5;28mself\u001b[39m.handles = \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1881\u001b[39m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1882\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1883\u001b[39m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1884\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcompression\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1885\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmemory_map\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1886\u001b[39m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m=\u001b[49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1887\u001b[39m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mencoding_errors\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstrict\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1888\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mstorage_options\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1889\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1890\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m.handles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1891\u001b[39m f = \u001b[38;5;28mself\u001b[39m.handles.handle\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\Geoffrey-RISA\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[39m, in \u001b[36mget_handle\u001b[39m\u001b[34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[39m\n\u001b[32m    868\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m    869\u001b[39m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[32m    870\u001b[39m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[32m    871\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m ioargs.encoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs.mode:\n\u001b[32m    872\u001b[39m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m873\u001b[39m         handle = \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    874\u001b[39m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    875\u001b[39m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    876\u001b[39m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m=\u001b[49m\u001b[43mioargs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    877\u001b[39m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m=\u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    878\u001b[39m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[32m    882\u001b[39m         handle = \u001b[38;5;28mopen\u001b[39m(handle, ioargs.mode)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: 'c:\\\\Users\\\\Geoffrey-RISA\\\\Documents\\\\GitHub\\\\AIMS-DSCBI\\\\notebooks\\\\assignments\\\\data\\\\rwa-cell-pop'"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(FILE_EXCEL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84a7a2f9",
   "metadata": {},
   "source": [
    "### Nightlight Dataset Variables (`cell-ntl-2015-2020-2024.csv`):\n",
    "Create the following temporal and development indicators:\n",
    "- **`nightlight_change_2015_2024`** - Percentage change in total nightlight from 2015 to 2024\n",
    "- **`mean_nightlight_change_2015_2024`** - Percentage change in mean nightlight from 2015 to 2024\n",
    "- **`lit_pixel_percentage`** - Use existing or calculate: `(lit_pixel_count / pixel_count) * 100`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59cee786",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d50596d1",
   "metadata": {},
   "source": [
    "### Data Integration:\n",
    "Merge the datasets using the appropriate column. \n",
    "\n",
    "## Part B: Exploratory Data Analysis\n",
    "\n",
    "### Correlation Analysis:\n",
    "1. **Correlation Heatmap**: Create a heatmap showing correlations between 10 key variables (mix of demographic, infrastructure, and nightlight variables). \n",
    "2. **Report the top 3 variable pairs** with the highest correlations and interpret their relationships.\n",
    "3. **Identify unexpected correlations** and discuss potential explanations.\n",
    "\n",
    "### Nightlight Trend Analysis:\n",
    "1. **District Ranking**: Report the **top 5 districts** with the highest nightlight growth (2015-2024) and **bottom 5 districts** with the most decline or lowest growth.\n",
    "2. **Lit Pixel Analysis**: Compare these districts using `lit_pixel_percentage` changes to understand whether growth represents intensification or spatial expansion.\n",
    "3. **Create visualizations** showing nightlight trends for these extreme districts.\n",
    "\n",
    "## Part C: Modeling\n",
    "\n",
    "### Multivariate Linear Regression:\n",
    "1. **Model Development**: Build a multivariate linear regression model predicting **population density** using both demographic and nightlight variables as predictors. Explore as many variables as possible at the beginning.\n",
    "2. **Variable Selection**: Test different combinations of variables and report the **top 3 most predictive variables** of population density.\n",
    "3. **Model Evaluation**: Report R-squared, coefficients, and statistical significance. Interpret what these results tell us about population-infrastructure relationships.\n",
    "\n",
    "\n",
    "\n",
    "## Notes and Other Requirements\n",
    "Please follow the genral guidelines below when preparing your analysis..\n",
    "\n",
    "### Statistical Analysis:\n",
    "- Properly handle missing data and outliers\n",
    "- Use appropriate statistical tests and report p-values\n",
    "- Calculate and interpret correlation coefficients\n",
    "- Validate regression assumptions (normality, homoscedasticity)\n",
    "\n",
    "### Data Management:\n",
    "- Document all data cleaning and aggregation steps using markdown \n",
    "- Ensure consistent district naming across datasets\n",
    "\n",
    "### Visualization Standards:\n",
    "- Create clear, publication-quality heatmaps with appropriate color scales\n",
    "- Design effective time series plots for nightlight trends\n",
    "- Include proper axis labels, titles, and legends\n",
    "- Use consistent formatting across all visualizations\n",
    "\n",
    "### Reporting Requirements:\n",
    "- Clearly state the top 3 most predictive variables with statistical justification\n",
    "- Provide ranked lists for nightlight growth districts with supporting metrics\n",
    "- Include model performance statistics and interpretation\n",
    "- Document all methodological choices and assumptions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
